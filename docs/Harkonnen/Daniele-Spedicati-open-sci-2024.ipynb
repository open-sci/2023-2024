{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Science Project Notebook 2024\n",
    "\n",
    "**Student:** Daniele Spedicati \n",
    "\n",
    "**Student number:** 1075755\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Harkonnen\n",
    "\n",
    "**Research question**\n",
    "\n",
    "Is that possible to create a new index of citations which contains typed citations where a peer review (citing entity) reviews (specific citation function) a publication (cited entity)? What is the necessary transformation of the Crossref dump necessary to create such an index to be compliant with the OpenCitations Data Model? What are the top publication venues in terms of the number of peer reviews received? How many peer reviews in Crossref are included in OpenCitations Meta? How many articles that have been reviewed by a peer review are included in OpenCitations Meta?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 \n",
    "\n",
    "### 21/03 - 27/03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26/03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A team meeting was held which resulted in the following conclusions:\n",
    "- The competency question has been divided in subquestions;\n",
    "- A first attempt to understand how to approach the subquestions has been made;\n",
    "- This reasoning resulted in a first attempt to the abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subquestions**\n",
    "\n",
    "1. Is that possible to create a new index of citations which contains typed citations where a peer review (citing entity) reviews (specific citation function) a publication (cited entity)?\n",
    "2. What is the necessary transformation of the Crossref dump necessary to create such an index to be compliant with the OpenCitations Data Model? \n",
    "3. What are the top publication venues in terms of the number of peer reviews received? \n",
    "4. How many peer reviews in Crossref are included in OpenCitations Meta? \n",
    "5. How many articles that have been reviewed by a peer review are included in OpenCitations Meta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resolution approaches**\n",
    "\n",
    "The solution here propoesed are purely speculative and based on a very shallow reading of different documentation material.\n",
    "\n",
    "1. The peer-reviewer role is covered in the OpenCitation Data Model by the [PRO](https://sparontologies.github.io/pro/current/pro.html#d4e825) ontology.\n",
    "A foaf:Agent pro:holdsRoleInTime pro:RoleInTime. \n",
    "The RoleInTime pro:withRole pro:Role, can express the role of peer-reviewer. \n",
    "The pro:RoleInTime pro:relatesToDocument foaf:Document.\n",
    "It is to be understood how to connect the review to the reviewed pubblication since there is no direct connection between the two of them (apparently).\n",
    "\n",
    "2. At first glence the dump result should be converted into from JSON (each key should have a property translating it). Than the doi property shold be processed by the OpenCitations Meta. To be better studied. \n",
    "\n",
    "The final two questions have not been addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract 1**\n",
    "\n",
    "The purpose of this study examines the feasibility of:\n",
    "- creating a new citation index that includes peer review interactions with publication.\n",
    "- The necessary transformation of the Crossref dumpe to create an index compliant with the OCDM.\n",
    "- To find out what are the venues with the highest number of peer reviews received, how many peer reviews present in Crossref are also included in OpenCitations Meta, and how many articles reviewed by a peer review are included in OpenCitations Meta.\n",
    "\n",
    "Study design/methodology/approach: Analyzing the Crossref dataset, we explore how to integrate peer review interactions into citation indices while ensuring compatibility with the OpenCitations Data Model.\n",
    "\n",
    "Findings: To the moment we don't have any relevant findings being that the work has just been started, we expect complexities involved in incorporating peer review data into citation indices, necessitating careful schema adjustments.\n",
    "\n",
    "Originality/value: This study contributes to improving scholarly metadata and understanding research impact by proposing a novel citation index that captures peer review interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Observations**\n",
    "\n",
    "\n",
    "- The term \"typed citation\" in this context could be translated as \"citation with defined type\". It refers to the ability to define specific types of citations within an index, such as a citation where a peer review (citing entity) reviews (specific citation function) a publication (cited entity). In this context, \"typed citation\" indicates that the citation is characterized by a specific relationship between the source and the target of the citation, which is defined based on a specific type of interaction between the two involved entities.\n",
    "\n",
    "-  The OpenCitations Meta database (http://opencitations.net/meta) stores and delivers bibliographic metadata for all publications involved in the OpenCitations Index. For each publication, the metadata exposed by OpenCitations Meta includes the publication's title, type, venue (e.g. journal name), volume number, issue number, page numbers, publication date, and identifiers such as Digital Object Identifiers (DOIs) and PubMed Identifiers (PMIDs). Currently OpenCitations Meta contains more than 90 million bibliographic entities that can be accessed and queried through a REST API and downloaded as a full dump (http://opencitations.net/download#meta)\n",
    "\n",
    "- Crossref is a not-for-profit membership association which aims at promoting the development and cooperative use of new and innovative technologies to speed and facilitate scientific and other scholarly research. Crossref is one of the ten International DOI registration agencies, and allows its members to register the DOIs of their publications. Each DOI registered in the Crossref system is associated with a URL to the publication’s webpage and accompanied with the metadata of the publications. Crossref provides a REST API to retrieve data about the entities and provides annual dumps. The entities Crossref comprises include also peer reviews of other articles, as shown in the exemplar result of the of the following API call:\n",
    "\n",
    "- COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations, is an RDF dataset containing details of all the citations that are specified by the open references to DOI-identified works present in Crossref, as of the latest COCI update. COCI does not index Crossref references that are not open, nor Crossref open references to entities that lack DOIs. The citations available in COCI are treated as first-class data entities, with accompanying properties including the citations timespan, modelled according to the OpenCitations Data Model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 and 3\n",
    "\n",
    "### 28/03 - 3/04 and 04/04 - 10/04\n",
    "#### 4/04\n",
    "- Had a call with the other members of the group to organize our work. Beside the organization we didn't do that much but that's ok. A good work follows a good organization. Being the Easter week and being that everyone was pretty much back at home we did the most we could do:\n",
    "    - We talked about the first draft of the DMP.\n",
    "    - We talked about how to proceed to get the information we need to create the new index requested by the research qurestion.\n",
    "\n",
    "#### 6/04\n",
    "- We met to get some work. We created, not without any perplexity, the two DMPs we needed. Some fields that we had to fill during this process confused us, but i guess it is normal for the moment. We decided to meet again soon to work on the protocol that we have to develop. More than that:\n",
    "    - I took a look at the crossref ocumentation, the one on [github] and the one on their [website]  for the rest api of crossref, thanks to that i have a clearer idea on how to get some data we will definitely need.\n",
    "    - While we were talking we came up with a solution(?) that can potentially be effective and that we also discussed the week before but now we are getting more confident with it. Basically it is a workaround: while on Crossref it is quite easy to get data about documents and their peer review (because in Crossref there is a direct link that connects the peer review with the resource receiving the review), the OpenCitation data model lacks direct links between cited articles and their respective peer reviews so we thought that an important property for our purpose could be the \"[is document context for]\" a property \"relating a document to the role for which that document provides the context (e.g. relating a document to the role of author or peer-reviewer of that document). In this case, roles like \"reviewer\" or \"peer reviewer\" are pertinent considerations. In simpler words: find the document for which in that moment the author covered the role of reviewer or peer reviewer and then allineate them to the results taken from crossref\n",
    "    - Thanks to my group i learned important informations such as the fact that we won't need to query an infinite amount of time crossref or find another workaround that maybe is in the documentation because we'll just need to use the appropriate [library].\n",
    "\n",
    "\n",
    "#### Doubts\n",
    "\n",
    "- While this seems a good plan to me (even if sometimes i stiil get stuck while trying to follow our own workaround), i have some perplexities regarding how we will pragmatically allineate all those results, how we will transform the format of results and all these kind of questions. I guess that when we'll start to develop our software everything will be clearer,hopefully, since the software itself is still one of my perplexities. But i trust myself and my groups, Furthermore, reassuring words echoing in my head, which I once read in a fairly famous book, also comfort me: \"Don't Panic. It's the first helpful or intelligible thing anybody's said to me all day.” so i won't. \n",
    "- We asked ourselves if there could be a problem regarding the fact that maybe while we're working the number of the reviews will grow.\n",
    "- I personally have a doubt regarding the fact that in this early stage of the work creating a DMP and a protocol without all the informations that we will have at the end of the project may be an iterative work that will require us many adjustments. I trust the fact that during the first lectures of this course Professor Peroni told us that it is the best choice to get these things done in advance\n",
    "\n",
    "\n",
    "### Future developments\n",
    "- As said before we will meet again to work on the protocol.\n",
    "- I have to get a deeper look at all the documentations needed to start developing the software.\n",
    "- After indulging in a binge of reading, it might be a good idea to adopt the same approach used for DMPs and the protocol, meaning starting work early so it doesn't become overwhelming later on.\n",
    "\n",
    "\n",
    "\n",
    "[github]: https://github.com/CrossRef/rest-api-doc#resource-components       \"Crossref\"\n",
    "[website]: https://www.crossref.org/documentation/retrieve-metadata/rest-api/        \"Crossref\"\n",
    "[is document context for]: https://sparontologies.github.io/pro/current/pro.html#d4e124    \"PRO ontology\"\n",
    "[library]: https://gitlab.com/crossref/crossref_commons_py    \"crossref_common_py\"\n",
    "[Daniele]: https://github.com/SpedicatiDaniele    \"Daniele\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4 \n",
    "#### 11/04 - 17/04\n",
    "#### 16/04\n",
    "\n",
    "Today i worked on the review about the protocol produced by team Atreides. I have to say that their protocol seems to be weel thought and conceived, of course being it in an early stage it's not possible to say where their research is going for now. I tried to focus on constructive suggestions mostly regarding the clarity about their exposition in the manipulation and in the interpretation of the results because honestly that is pretty much all that i have to say about it. All the parts about how to implement their software seem to be quite solid for now, the chain of query-data manipulation seem to be effective in producing answer they may need.\n",
    "Also confronting with the other team we found out that pasting the doi of the DMPs on Qeios lead to nowhere, this may be something to ask for further clarifications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 5 \n",
    "#### 18/04 - 25/04\n",
    "Me and the rest of the gorup saw eachother to actually define a plan to develop the software. Using our dear old pen and paper we spent some days trying to crack the best possilble strategy to actually retrieve and use whatever we needed. As time get by is is kind of frustrating see that every day studying a little bit more reveal to us that the accomplishment we thought we had achieved the days before are not that good. But it is what it is. \n",
    "We are starting to think that we will need to adjust the description of the protocol deeply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 \n",
    "#### 26/04 - 2/05\n",
    "As i stated in other entries of this diary getting to work is kind of strange beacuse one day you do something that looks like progress and the day after it is probably useless. A huge problem we have is the size of the Crossref dump we need to have for our research. It is prohibitive for our machines that will probably have problems processing it during all the phases of this project. We asked for help about it\n",
    "In the meantime we started using Colab to see if we could run some code efficiently one some sample of data retrieved from the Crossref API. We managed to devise a first version of the class PeerReview that we will likely use in the end of the project when we'll need to populate our data with the right characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 7 \n",
    "#### 3/05 - 9/05\n",
    "Between classes, exams and personal matters, we didn't had the chance to work a lot this week. We still had some work done regarding the pre-processing phase. We managed to have our Crossref dump to be divided in 18 zipped parts, it is easier to deal with. Even if the download of each single part required more or less 45 minutes. A first try to work on the files without extracting them made us realize that time is not in our favor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 8 \n",
    "#### 10/05 - 17/05\n",
    "#### 13/05/2024\n",
    "\n",
    "Much of this week has been devoted to understanding what and how to efficiently extract from the individual chunks of the crossref dump. We made many attempts, most of which resulted in failure due to the very large amount of data and the computational capabilities of our computers. As a result of these repeated ‘failures’, we had to devise an efficient way to handle this enormous amount of data, and considering that our extraction tests often took us at least 45 minutes per file, much of that time was spent staring at the computer grinding out data. I must say that all this gave me a bit of a sense of helplessness, but then again, the data pre-processing phase is always like that.\n",
    "\n",
    "\n",
    "### 14/05/2024\n",
    "On my own, I tried alternative solutions, one of which was to use Spark. Initially (and unsuccessfully) I tried setting everything up on my main pc, using this Windows as my operating system, which took me almost half a day that I could have used more productively in hindsight. The same evening, on a secondary PC I have at home and which uses Linux as its operating system, I continued this experiment which promises. \n",
    "\n",
    "\n",
    "### 15/05/2024\n",
    "\n",
    "Some problems derived from the approach described above made me give up. Firstly, I felt that being the only one who could use Spark efficiently in my group would create more problems than anything else. Secondly, my secondary PC is not powerful enough to replace the collective effort of 4 group members. Thirdly, studying a framework like spark would have taken time to learn how to use it decently and how to explain it above all. Basically I wasted some time but during the evaluation phase of this approach it might have seemed like a good idea so it was worth a try especially because I knew I could count on the efforts of the other members of my group who in the meantime continued to work on solving the problems described above in a more \"canonical\" way.\n",
    "\n",
    "### 16/05/2024\n",
    "\n",
    "We are starting to think that we will probably need to see eachoter every day untill the presentation. We are not getting quite good results for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weeks 9/10 \n",
    "#### 18/05 - 27/05\n",
    "I will write a single entry for this workweek since we saw each other and worked incessantly every day. Finally, we achieved promising results through the use of more suitable data structures and especially with the help of Python libraries that maximize the computational power of each machine. Another solution was to implement a work logic that involved reading, analyzing, and transcribing the necessary information in small batches. On average, each chunk took about an hour to extract data regarding peer-reviewed and non-peer-reviewed items. To work more efficiently, we divided the tasks into thematic sections. I mainly focused on data processing, which includes extraction, cleaning, and organization. Fortunately, for the peer-reviewed data, we were able to use ready-made codes provided by OpenCitations (COCI). An honorable mention is necessary for Ivan Heibi, to whom we asked several questions to better manage some sections of our project.\n",
    "\n",
    "I spent a couple of days feeling nervous because, during the join phase of the dataframes concerning peer-reviewed and non-peer-reviewed items, I obtained results that were completely different from what we expected. These two days dedicated to solving memory issues caused by handling 36 large dataframes and resolving unexpected results were not very productive. I believe I entered a state of grace at sunset this week because, on my way home, I would think of a solution that I could implement after some effort. I must say that without external help (such as the vast variety of internet resources and suggestions from more experienced people), I would have needed more time to solve these problems.\n",
    "\n",
    "In essence, the memory issues were resolved thanks to Polars, which allows dataframes to be read without loading them into memory until operations are applied, and it generally performs better with large amounts of data (thank you for existing, scan_csv and sink_csv). The issue with the unexpected results was due to my complete oversight of a warning given at the start of this project: the normalization of DOIs. Once normalized, the match accuracy approached 100% (only 10 DOIs were not found out of nearly half a million).\n",
    "\n",
    "The next challenge was converting all these software products into programs callable from terminals, where the logic of class-based programming was present. Dusting off the knowledge acquired during the Data Science course, we managed to solve this with somewhat mixed success. A significant amount of time was dedicated to creating the run.py file, which was supposed to gather everything we had produced into a single file. The creation of this software was completed just in time because shortly before the deadline, we realized it wasn't working. This problem arose because all the issues caused by data processing made us neglect other tasks of this project such as reviewing the DMP, reviewing the protocol, writing the article, creating the slides, and creating visualizations of the results. All tasks that we eventually managed to successfully resolve but that clearly required a lot of effort.\n",
    "\n",
    "I would like to thank my colleagues who had to endure my obsessions at times, which did not always yield results. Without them, I wouldn't have been able to solve several problems and, most importantly, complete this project, which required a 360-degree effort. Overall, we are satisfied with the results we have achieved. We are aware that this project can probably be improved, which we will need to do anyway, but we can still say we are happy with the results obtained because we believe that the creation of PROCI (our Peer Review OpenCitations Index) can be a valuable contribution. This awareness makes us happy and gives us a sense of fulfillment, knowing that we have created something potentially useful.\n",
    "\n",
    "Post Credit:\n",
    "I think the presentation went well; we are awaiting feedback from the professor. Now begins the study of the theoretical part for the second part of the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second phase\n",
    "\n",
    "#### Lab Diary Entry - November 15th\n",
    "\n",
    "After presenting our project to industry experts, we received valuable feedback from our professor regarding how to adapt to the requests that emerged. The main suggestions included adjustments to the Data Management Plan (DMP), revisions to the protocol, and updates to the draft article. \n",
    "\n",
    "One key request was to include a reflective section about the authors in the paper itself, highlighting their contributions and perspectives. \n",
    "\n",
    "Between October and November, we focused on addressing these points. The DMP was updated to provide clearer guidelines on data handling and compliance. The protocol underwent several refinements to ensure alignment with the revised project scope. For the article, we introduced a dedicated section discussing the roles, motivations, and learnings of each team member, tying this to the broader goals of the study. \n",
    "\n",
    "These changes have brought more depth and coherence to the project, preparing it for final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 11/12\n",
    "### 21/10 - 03/11 \n",
    "\n",
    "\n",
    "During the first two weeks of work, we focused on revising the Data Management Plan (DMP), refining the protocol, and addressing the specific points highlighted by the professor in the article. \n",
    "\n",
    "This phase involved aligning the DMP with best practices for data organization and security, ensuring that the protocol met the required standards, and enhancing the article’s structure and clarity based on the feedback received. These initial steps laid a strong foundation for the subsequent stages of the project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 13/14\n",
    "### 04/11 - 17/11\n",
    "\n",
    "In the following two weeks, we focused on integrating the missing data related to the authors. Specifically, we conducted the following analyses:  \n",
    "\n",
    "- Comparison of anonymous vs. non-anonymous peer reviews.  \n",
    "- Identification of top venues based on the number of anonymous and non-anonymous peer reviews received.  \n",
    "- Analysis of the number of authors involved in non-anonymous peer reviews.  \n",
    "\n",
    "After completing these analyses, we incorporated the results into the article, ensuring that the findings were clearly presented and aligned with the paper’s overall narrative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
