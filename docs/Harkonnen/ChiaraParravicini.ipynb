{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Science's Notebook 23/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chiara Parravicini - Team Harkonnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question:\n",
    "\n",
    "Is that possible to create a new index of citations which contains typed citations where a peer review (citing entity) reviews (specific citation function) a publication (cited entity)? What is the necessary transformation of the Crossref dump necessary to create such an index to be compliant with the OpenCitations Data Model? What are the top publication venues in terms of the number of peer reviews received? How many peer reviews in Crossref are included in OpenCitations Meta? How many articles that have been reviewed by a peer review are included in OpenCitations Meta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-exam: December\n",
    "We finished working on refining our project following the professor's suggestions.\n",
    "I mostly dealt with the Protocol. It turned out we didn't quite get the purpose of this document: we thought it would be useful to describe the details of the code of our software, but as the professor pointed out it should be a more abstract description of the workflow and the reasoning we followed. As a consequence, revising the document was demanding; at the same time, reading other protocols for reference and spending more time working on ours made me realize the actual importance of this kind of documentation of a research.\n",
    "\n",
    "We finally submitted the project: it's been a hell of a ride but I think we're all proud of both the process and the result. Having worked on it so long, even if intermittently, also made me realize how we evolved in our approach to coding and everything that revolves around the development of a software. I'm very grateful to my team mates; as I wrote before, collaborating so closely with them has been both challenging and enriching: sometimes it's been hard to listen and really understand each other, but often we filled each other's gaps, in terms of ideas, energies, resources.\n",
    "\n",
    "###  Post-exam: November\n",
    "\n",
    "Revising the foundational elements of the project was the main task. We addressed the following points:\n",
    "- Adding auhtor information so that we can compare anonymous vs. non-anonymous peer reviews and add this layer of analysis to our research;\n",
    "- Updating the Data Management Plan (DMP) to improve clarity and better align with compliance standards;\n",
    "- Refining the protocol's whole structure;\n",
    "- Revising the article.\n",
    "\n",
    "I especially took care of modifying the PeerExtractor class to include author information and of redrafting the protocol.\n",
    "\n",
    "### Weeks 9/10: 18/05 - 27/05\n",
    "\n",
    "This week we met daily, trying to split tasks but also helping each other if needed. I worked with Matteo for the data extraction and processing phase and with Daniele and Nicole for the post-processing and data analysis. Finding the answer to the first two research questions (so basically the creation of peer review entity with all the metadata needed to make an index compliant with the OCDM) was for sure more challenging and time consuming then the other three. \n",
    "Working so closely with my team mates has been equally challenging and enriching: sometimes it's hard to listen and really understand each other (at this point we often are convinced to already know what the other is proposing/pointing out so we don't actually pay attention to what they say), but often we fill each other's gaps, in terms of ideas, energies, resources.\n",
    "Despite setbacks, we managed to finalize our software, prepare visuals, and complete the article. \n",
    "\n",
    "### Week 8: 10/05 - 17/05\n",
    "\n",
    "This week revolved around tackling data pre-processing challenges and starting to work on the article. Matteo is experimenting with Spark, Daniele and Nicole are working on the theoretical premise of the article and on the RDF graph creation (preparing it for when we'll have all the data we need) and I'm experimenting parallel processing to speed up the process.\n",
    "\n",
    "### Week 7: 3/05 - 9/05\n",
    "\n",
    "While balancing classes and exams, I helped preprocess our Crossref dump. Ivan kindly split the Crossref dump into chunks, making it more manageable. Now each of us has 4/5 chunks to deal with, so we can actually start working with real data. \n",
    "The main problem we're facing is that for the first time since we started programming we're dealing with scripts that take 30/45 minutes to run, so we have to test carefully our strategies before applying them to real data, to avoid wasting time.\n",
    "The most compelling question we have to answer is how to connect the peer review's metadata (citing entity) with the metadata of the article it refers to (cited entity). This is more or less the thought process we followed:\n",
    "Should we take each cited doi from the peer review metadata and look for it in the dump? But each of us has only a part of the dump, so it doesn't work and also it's very time and resource consuming.\n",
    "--> We first narrow down the resources in Crossref that can be cited entity (so basically in our case it's everything that's not a peer review) and later we look for matches with the cited dois in the peer reviews' metadata.\n",
    "This realization (which was actually suggested by the professor in early stages, but probably at the time we didn't quite get the grasp of the problem) is been a big step foreward, but there's still a lot to do.\n",
    "\n",
    "### Week 6: 26/04 - 2/05\n",
    "\n",
    "Our primary challenge was the size of the Crossref dump (we thought about a couple of ways to tackle the problem, like for example using Colab). We asked for help to the professor. We tried to create a first draft the PeerReview class. \n",
    "\n",
    "### Week 5: 18/04 - 25/04\n",
    "\n",
    "We met to outline a strategy for developing the software. There's a lot of trial and error going on and I have a feeling we are overcomplicating stuff. As usual, probably we should start making simple drafts of scripts, but instead we end up talking about the abstract strategies behind it and we get a bit lost.\n",
    "\n",
    "### Week 4: 11/04 - 17/04\n",
    "\n",
    "This week we worked on the revision of Atreides' team materials. I reviewed the DMP. Their work was well-structured, though I made very few suggestion; also we are in a very early stage of our project, so I reckon it's been difficult for both teams to add a lot of detail. \n",
    "I think it was useful to try to be the reviewer of a colleague's work: it's a delicate role, one needs to be both strict and understanding (because no one needs criticism which is an end in itself). Also, since we are directly dealing with peer reviews,  trying to contribute to the reviewers' recognition, I think it's been important to experience taking this role even if for a small task.\n",
    "\n",
    "### Weeks 2/3: 28/03 - 10/04\n",
    "\n",
    "In these weeks we managed to:\n",
    "\n",
    "- Create drafts for two Data Management Plans (DMPs).\n",
    "- Begin planning our protocol.\n",
    "\n",
    "This period also involved exploring the Crossref API and brainstorming how to bridge gaps in the OpenCitations Data Model. Personally I sometimes struggle to keep up with my teammates' pace when they're brainstorming about possible ways to build the index and about the necessary steps to make it compliant with the OCDM, but I try not to panic, trust them and trust also my capability to undersand everything eventually.\n",
    "\n",
    "### Week 1 | 21/03 -> 27/03\n",
    "#### 26/03/2024\n",
    "\n",
    "- preliminary research on Crossref and OpenCitations Meta \n",
    "- group meeting discussing about our ideas on how to approach the different steps of the research question\n",
    "- writing a first version of the Abstract of the short article we'll have to write at the end of the project, starting to imagine how we will conduct our research and what could be the possible results\n",
    "\n",
    "**Questions:**\n",
    "- how can we use the class Reviewer (already existing in OpenCitations Ontology) to get the reviews (citing entity) we need for our index?\n",
    "- will it be necessary to create a specific object relation for indicating the relation between the review and the reviewed document? There are already existing properties ( \"is document context for\") but they connect the reviewer with the document "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
